{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fce05fce-a1fd-49a4-972d-46860777d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vocabulary import normalizeString, vocabulary, unicodetoascii\n",
    "import itertools\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a386ced2-f4d4-4dcf-affa-3c945f37d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "SOS = 1\n",
    "EOS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194c8f8c-d33c-4dea-be0a-188f09e384ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"data/formatted_movie_lines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48ece6e-fc78-4896-a92d-5a5372ebda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(datafile, encoding=\"utf-8\").read().strip().split(\"\\n\\n\")\n",
    "pairs = [[normalizeString(s) for s in pair.split(\"\\t\")] for pair in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44059c9-aa7c-45bb-840d-d1d8c1fb2a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221282"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e0da060-2fd0-4983-be45-b5e443b9f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = vocabulary(\"Cornell Movie Dialogues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de6516f-30bd-4dce-9823-83e55e697534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a bit more cleaning, so well remove any sentances that are too long\n",
    "def filterpair(p, max_length=10):\n",
    "    return len(p[0].split()) <= max_length and len(p[1].split()) <= max_length\n",
    "\n",
    "pairs = [pair for pair in pairs if filterpair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30d31f1-fc1c-42ba-bb9a-77ebfc933d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75026"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f57a7aec-f702-4395-a343-935c3501863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['that s because it s such a nice one .', 'forget french .'],\n",
       " ['there .', 'where ?'],\n",
       " ['you have my word . as a gentleman', 'you re sweet .'],\n",
       " ['hi .', 'looks like things worked out tonight huh ?'],\n",
       " ['you know chastity ?', 'i believe we share an art instructor'],\n",
       " ['have fun tonight ?', 'tons'],\n",
       " ['well no . . .', 'then that s all you had to say .'],\n",
       " ['then that s all you had to say .', 'but'],\n",
       " ['but', 'you always been this selfish ?'],\n",
       " ['do you listen to this crap ?', 'what crap ?']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "527b4732-1a82-45ee-b0e8-177eac5a3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimRareWords(vocab, pairs, min_count = 3):\n",
    "    \n",
    "    vocab.trim(min_count=min_count)\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_ = pair[0]\n",
    "        reply_ = pair[1]\n",
    "        keepinput, keepreply = True, True\n",
    "        for word in input_.split(\" \"):\n",
    "            if word not in vocab.word2index:\n",
    "                keepinput = False\n",
    "                break\n",
    "        for word in reply_.split(\" \"):\n",
    "            if word not in vocab.word2index:\n",
    "                keepreply = False\n",
    "                break\n",
    "        if keepinput and keepreply:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(f\"After trimming kept {len(keep_pairs)} out of {len(pairs)}\")\n",
    "    \n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "521d0b42-26ac-49f8-99c4-1e40002a379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20093\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    corpus.addSentance(pair[0])\n",
    "    corpus.addSentance(pair[1])\n",
    "\n",
    "print(corpus.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc3437a-390c-4a3e-a7d4-cef7ff5a482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After trimming kept 62810 out of 75026\n"
     ]
    }
   ],
   "source": [
    "cleaned_pairs = trimRareWords(corpus, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdd9a599-27a2-4abc-8e1b-c992bf8cd43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['that s because it s such a nice one .', 'forget french .'],\n",
       " ['there .', 'where ?'],\n",
       " ['you have my word . as a gentleman', 'you re sweet .'],\n",
       " ['hi .', 'looks like things worked out tonight huh ?'],\n",
       " ['have fun tonight ?', 'tons'],\n",
       " ['well no . . .', 'then that s all you had to say .'],\n",
       " ['then that s all you had to say .', 'but'],\n",
       " ['but', 'you always been this selfish ?'],\n",
       " ['do you listen to this crap ?', 'what crap ?'],\n",
       " ['what good stuff ?', 'the real you .']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09ed4a0d-84d5-4763-8a9a-ca2fe05088ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexfromSentance(vocab:vocabulary, sentance:str):\n",
    "    return [vocab.word2index[word] for word in sentance.split(\" \")] + [EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0efea256-5019-4813-96b2-901bfae6e8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 11, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexfromSentance(corpus, cleaned_pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06bb3376-3832-4703-b0d9-66e313e75e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for pair in cleaned_pairs[:10]:\n",
    "    inputs.append(indexfromSentance(corpus, pair[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47d24fa2-bf40-4fe3-bea5-c6468356c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropading(l, fillvalue = 0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3c17280-c2a6-494e-9ff4-4f8c36e6037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarymatrix(l, value=0):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e36655cf-6e94-4971-8654-e995761bf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = zeropading(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecf0aade-3956-46b3-a35a-187e7175a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 5, 6, 4, 7, 8, 9, 10, 11, 2],\n",
       " [14, 11, 2],\n",
       " [17, 18, 19, 20, 11, 21, 8, 22, 2],\n",
       " [25, 11, 2],\n",
       " [18, 40, 31, 16, 2],\n",
       " [42, 43, 11, 11, 11, 2],\n",
       " [44, 3, 4, 45, 17, 46, 47, 48, 11, 2],\n",
       " [49, 2],\n",
       " [54, 17, 55, 47, 52, 56, 16, 2],\n",
       " [57, 58, 59, 16, 2]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fec31028-4e7e-4375-8846-2237127474e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 14, 17, 25, 18, 42, 44, 49, 54, 57),\n",
       " (4, 11, 18, 11, 40, 43, 3, 2, 17, 58),\n",
       " (5, 2, 19, 2, 31, 11, 4, 0, 55, 59),\n",
       " (6, 0, 20, 0, 16, 11, 45, 0, 47, 16),\n",
       " (4, 0, 11, 0, 2, 11, 17, 0, 52, 2),\n",
       " (7, 0, 21, 0, 0, 2, 46, 0, 56, 0),\n",
       " (8, 0, 8, 0, 0, 0, 47, 0, 16, 0),\n",
       " (9, 0, 22, 0, 0, 0, 48, 0, 2, 0),\n",
       " (10, 0, 2, 0, 0, 0, 11, 0, 0, 0),\n",
       " (11, 0, 0, 0, 0, 0, 2, 0, 0, 0),\n",
       " (2, 0, 0, 0, 0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8bfcb70-71e4-4548-9dd0-dc720c9352a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = binarymatrix(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d1bf33b-4fff-417b-be94-c661d506eed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e05ccf0-f8a4-48b1-802a-8f511aa09fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns padded input sequence tensor as well as tensor of lengths for each of the padded seq in the batc\n",
    "def inputVar(l:list, vocab:vocabulary):\n",
    "    indexes_batch = [indexfromSentance(vocab, sentance) for sentance in l]\n",
    "    lengths = torch.tensor([len(index_array) for index_array in indexes_batch])\n",
    "    padlist = zeropading(indexes_batch)\n",
    "    padvar = torch.LongTensor(padlist)\n",
    "    return padvar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35df8b76-8349-4a6b-8722-b17ae19f4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns padded target sequence tensor, padding mask and maax target length\n",
    "def outputVar(l:list, vocab:vocabulary):\n",
    "    indexes_batch = [indexfromSentance(vocab, sentance) for sentance in l]\n",
    "    max_target_len = max([len(index_array) for index_array in indexes_batch])\n",
    "    padlist = zeropading(indexes_batch)\n",
    "    mask = binarymatrix(padlist)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padvar = torch.LongTensor(padlist)\n",
    "    return padvar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9983aa17-2a38-4f94-bcfe-bf516ef47169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepares the data for training for a given batch of pairs\n",
    "def batch2traindata(vocab, pair_batch):\n",
    "    #Sort the question answers pairs in descending order\n",
    "    pair_batch.sort(key=lambda x:len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, vocab)\n",
    "    output, mask, max_target_len = outputVar(output_batch, vocab)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5c2d509-369a-4e4e-a5b4-55d2c9bee942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation of preprocessing steps\n",
    "batch_size = 5\n",
    "input_seq, lengths, target_seq, target_mask, max_target_length = batch2traindata(corpus, [random.choice(cleaned_pairs) for _ in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a01ceb19-616e-4992-a735-2b57bffb7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 153,  113,   34,  550, 1483],\n",
      "        [  34,   34,  108, 6394,   16],\n",
      "        [ 101,   67,  285,   16,    2],\n",
      "        [ 102,  882,    6,    2,    0],\n",
      "        [ 307, 1114,  158,    0,    0],\n",
      "        [  82,  225,   11,    0,    0],\n",
      "        [  60,   16,    2,    0,    0],\n",
      "        [ 246,    2,    0,    0,    0],\n",
      "        [  11,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b39daa5-24b2-4f3e-baf1-ac9e625353b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  8,  7,  4,  3])\n"
     ]
    }
   ],
   "source": [
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad0da604-0c9b-4783-a62b-437d9e34136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 860,  344,  327,   66,  266],\n",
      "        [8058, 1184, 1544, 3183,   32],\n",
      "        [ 640,   11, 2398,   67,   11],\n",
      "        [  11,   17,   27, 6263,  143],\n",
      "        [   2,  543,   93,   73,   10],\n",
      "        [   0,  183,   11,    2,   16],\n",
      "        [   0,  522,    2,    0,    2],\n",
      "        [   0,   47,    0,    0,    0],\n",
      "        [   0, 1704,    0,    0,    0],\n",
      "        [   0,   11,    0,    0,    0],\n",
      "        [   0,    2,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a719f60a-6d6a-42e8-be88-db42edc41ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f65e55af-3c3c-4fae-b2f2-80608b4a7769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8010e9a-4b3a-4839-aece-432e3aefb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = torch.nn.GRU(input_size = 5, hidden_size = 3, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce60aa9d-7d75-44f5-83de-46f86c634738",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c66f2455-e0eb-4245-b344-b301528dd6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7606, -0.6435, -0.1769, -1.2964, -0.9328],\n",
       "         [-0.5316, -0.5640,  0.0882,  1.3835,  0.3539],\n",
       "         [ 1.8324, -0.2292, -0.8020, -1.4747, -0.0541],\n",
       "         [-0.6323, -0.7169, -0.2268,  1.9690,  0.1143],\n",
       "         [ 0.6190,  0.8411, -2.2479,  0.2791, -0.6485]],\n",
       "\n",
       "        [[-0.5636, -0.2744,  1.0614,  1.6762, -0.2682],\n",
       "         [-1.8209,  0.5697, -0.6093, -1.2058,  0.9373],\n",
       "         [-0.3847, -0.2412, -0.3489,  0.3419, -1.9268],\n",
       "         [ 0.0416,  0.3064, -0.1255, -0.9199, -0.6506],\n",
       "         [-0.2896, -1.4179,  1.7530,  0.1146,  0.2073]],\n",
       "\n",
       "        [[-1.7934,  1.5147,  1.4379,  0.9670,  1.0614],\n",
       "         [-0.4330,  0.3590, -0.3347,  0.6064,  0.1310],\n",
       "         [ 0.1455, -0.1465,  0.2352, -0.0569,  0.2094],\n",
       "         [-0.5671, -0.6823,  0.7690, -1.1584,  0.2873],\n",
       "         [ 1.7295, -1.0829, -0.5514,  2.2988, -0.1104]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20f194ea-bcfc-47c6-ba14-8abe02af79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(6, 7) #(batch_size, seq_len or max words per bach)\n",
    "lengths = [7,7,6,5,4,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "593de5af-cc71-4310-b016-2d102d1d5d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 7, 6, 5, 4, 2]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18ebc41a-3424-4774-8a59-f9db0ff551da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6346, 0.4711, 0.9906, 0.7849, 0.7462, 0.5860, 0.5907],\n",
       "        [0.8719, 0.9433, 0.5214, 0.8487, 0.1704, 0.8424, 0.5195],\n",
       "        [0.4170, 0.1870, 0.0618, 0.3893, 0.1823, 0.8014, 0.0000],\n",
       "        [0.3333, 0.0549, 0.3940, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3459, 0.1796, 0.0064, 0.5855, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3830, 0.3656, 0.8027, 0.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0c1e668-9dd8-4581-8d2d-286a4a576fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.nn.utils.rnn.pack_padded_sequence(a, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00cbb49b-c305-455c-a837-e494fdadb241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6346, 0.8719, 0.4170, 0.3333, 0.3459, 0.3830, 0.4711, 0.9433, 0.1870,\n",
       "        0.0549, 0.1796, 0.3656, 0.9906, 0.5214, 0.0618, 0.3940, 0.0064, 0.7849,\n",
       "        0.8487, 0.3893, 0.0000, 0.5855, 0.7462, 0.1704, 0.1823, 0.0000, 0.5860,\n",
       "        0.8424, 0.8014, 0.5907, 0.5195])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c2fad74-4b0e-4036-bcdc-bde8468788dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 5, 5, 4, 3, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cff46d3a-62e0-4247-810c-33e6a0d6231f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6346, 0.8719, 0.4170, 0.3333, 0.3459, 0.3830])\n",
      "tensor([0.4711, 0.9433, 0.1870, 0.0549, 0.1796, 0.3656])\n",
      "tensor([0.9906, 0.5214, 0.0618, 0.3940, 0.0064])\n",
      "tensor([0.7849, 0.8487, 0.3893, 0.0000, 0.5855])\n",
      "tensor([0.7462, 0.1704, 0.1823, 0.0000])\n",
      "tensor([0.5860, 0.8424, 0.8014])\n",
      "tensor([0.5907, 0.5195])\n"
     ]
    }
   ],
   "source": [
    "cutoff = 0\n",
    "for i in targets[1]:\n",
    "    print(targets[0][cutoff:cutoff+i])\n",
    "    cutoff += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fa4ab30-1d6c-47e7-8827-03d6561aab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(5,5) #(batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0332749d-2e2d-48b0-80e3-72405d43ada6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5633, 0.5129, 0.8349, 0.5787, 0.7113],\n",
       "        [0.7678, 0.4710, 0.0760, 0.6818, 0.1525],\n",
       "        [0.0555, 0.3180, 0.1772, 0.6100, 0.9287],\n",
       "        [0.7592, 0.5092, 0.7764, 0.2982, 0.7805],\n",
       "        [0.8202, 0.4984, 0.6043, 0.1431, 0.4397]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so each value in any row is basically the encoded word\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "824179fc-6ef2-47fe-aa24-fcfe60877a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.nn.functional.softmax(b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7971551-495f-4c77-86bf-47fadf3d9b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1839, 0.1749, 0.2413, 0.1867, 0.2132],\n",
       "        [0.2701, 0.2008, 0.1352, 0.2479, 0.1460],\n",
       "        [0.1322, 0.1719, 0.1493, 0.2301, 0.3165],\n",
       "        [0.2248, 0.1751, 0.2287, 0.1418, 0.2296],\n",
       "        [0.2687, 0.1947, 0.2165, 0.1365, 0.1836]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2214727-a084-4d89-b937-b1584877289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd0a3a96-4e07-4ec6-ace8-085f9287cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Negetive Log Liklehood Loss\n",
    "def maskNLLLoss(decoder_out, target, mask, device):\n",
    "    ntotal = mask.sum()\n",
    "    target = target.view(-1,1)\n",
    "    #Decoder output shape: (batch_size, vocab_size), targets_size = (batch_size,1)\n",
    "    gathered_tensor = torch.gather(decoder_out,1,target)\n",
    "    cross_entropy = -torch.log(gathered_tensor)\n",
    "    loss = cross_entropy.masked_select(mask)\n",
    "    loss = loss.mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, ntotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30d428-bb53-4c5e-9719-ac99f14743b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
