{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fce05fce-a1fd-49a4-972d-46860777d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Vocabulary import normalizeString, vocabulary, unicodetoascii\n",
    "import itertools\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a386ced2-f4d4-4dcf-affa-3c945f37d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "SOS = 1\n",
    "EOS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194c8f8c-d33c-4dea-be0a-188f09e384ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"data/formatted_movie_lines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48ece6e-fc78-4896-a92d-5a5372ebda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(datafile, encoding=\"utf-8\").read().strip().split(\"\\n\\n\")\n",
    "pairs = [[normalizeString(s) for s in pair.split(\"\\t\")] for pair in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44059c9-aa7c-45bb-840d-d1d8c1fb2a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221282"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e0da060-2fd0-4983-be45-b5e443b9f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = vocabulary(\"Cornell Movie Dialogues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de6516f-30bd-4dce-9823-83e55e697534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a bit more cleaning, so well remove any sentances that are too long\n",
    "def filterpair(p, max_length=10):\n",
    "    return len(p[0].split()) <= max_length and len(p[1].split()) <= max_length\n",
    "\n",
    "pairs = [pair for pair in pairs if filterpair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30d31f1-fc1c-42ba-bb9a-77ebfc933d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75026"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f57a7aec-f702-4395-a343-935c3501863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['that s because it s such a nice one .', 'forget french .'],\n",
       " ['there .', 'where ?'],\n",
       " ['you have my word . as a gentleman', 'you re sweet .'],\n",
       " ['hi .', 'looks like things worked out tonight huh ?'],\n",
       " ['you know chastity ?', 'i believe we share an art instructor'],\n",
       " ['have fun tonight ?', 'tons'],\n",
       " ['well no . . .', 'then that s all you had to say .'],\n",
       " ['then that s all you had to say .', 'but'],\n",
       " ['but', 'you always been this selfish ?'],\n",
       " ['do you listen to this crap ?', 'what crap ?']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "527b4732-1a82-45ee-b0e8-177eac5a3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimRareWords(vocab, pairs, min_count = 3):\n",
    "    \n",
    "    vocab.trim(min_count=min_count)\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_ = pair[0]\n",
    "        reply_ = pair[1]\n",
    "        keepinput, keepreply = True, True\n",
    "        for word in input_.split(\" \"):\n",
    "            if word not in vocab.word2index:\n",
    "                keepinput = False\n",
    "                break\n",
    "        for word in reply_.split(\" \"):\n",
    "            if word not in vocab.word2index:\n",
    "                keepreply = False\n",
    "                break\n",
    "        if keepinput and keepreply:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(f\"After trimming kept {len(keep_pairs)} out of {len(pairs)}\")\n",
    "    \n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "521d0b42-26ac-49f8-99c4-1e40002a379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20093\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    corpus.addSentance(pair[0])\n",
    "    corpus.addSentance(pair[1])\n",
    "\n",
    "print(corpus.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc3437a-390c-4a3e-a7d4-cef7ff5a482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After trimming kept 62810 out of 75026\n"
     ]
    }
   ],
   "source": [
    "cleaned_pairs = trimRareWords(corpus, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdd9a599-27a2-4abc-8e1b-c992bf8cd43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['that s because it s such a nice one .', 'forget french .'],\n",
       " ['there .', 'where ?'],\n",
       " ['you have my word . as a gentleman', 'you re sweet .'],\n",
       " ['hi .', 'looks like things worked out tonight huh ?'],\n",
       " ['have fun tonight ?', 'tons'],\n",
       " ['well no . . .', 'then that s all you had to say .'],\n",
       " ['then that s all you had to say .', 'but'],\n",
       " ['but', 'you always been this selfish ?'],\n",
       " ['do you listen to this crap ?', 'what crap ?'],\n",
       " ['what good stuff ?', 'the real you .']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09ed4a0d-84d5-4763-8a9a-ca2fe05088ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexfromSentance(vocab:vocabulary, sentance:str):\n",
    "    return [vocab.word2index[word] for word in sentance.split(\" \")] + [EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0efea256-5019-4813-96b2-901bfae6e8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 11, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexfromSentance(corpus, cleaned_pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06bb3376-3832-4703-b0d9-66e313e75e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for pair in cleaned_pairs[:10]:\n",
    "    inputs.append(indexfromSentance(corpus, pair[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47d24fa2-bf40-4fe3-bea5-c6468356c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropading(l, fillvalue = 0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3c17280-c2a6-494e-9ff4-4f8c36e6037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarymatrix(l, value=0):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e36655cf-6e94-4971-8654-e995761bf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = zeropading(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecf0aade-3956-46b3-a35a-187e7175a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 5, 6, 4, 7, 8, 9, 10, 11, 2],\n",
       " [14, 11, 2],\n",
       " [17, 18, 19, 20, 11, 21, 8, 22, 2],\n",
       " [25, 11, 2],\n",
       " [18, 40, 31, 16, 2],\n",
       " [42, 43, 11, 11, 11, 2],\n",
       " [44, 3, 4, 45, 17, 46, 47, 48, 11, 2],\n",
       " [49, 2],\n",
       " [54, 17, 55, 47, 52, 56, 16, 2],\n",
       " [57, 58, 59, 16, 2]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fec31028-4e7e-4375-8846-2237127474e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 14, 17, 25, 18, 42, 44, 49, 54, 57),\n",
       " (4, 11, 18, 11, 40, 43, 3, 2, 17, 58),\n",
       " (5, 2, 19, 2, 31, 11, 4, 0, 55, 59),\n",
       " (6, 0, 20, 0, 16, 11, 45, 0, 47, 16),\n",
       " (4, 0, 11, 0, 2, 11, 17, 0, 52, 2),\n",
       " (7, 0, 21, 0, 0, 2, 46, 0, 56, 0),\n",
       " (8, 0, 8, 0, 0, 0, 47, 0, 16, 0),\n",
       " (9, 0, 22, 0, 0, 0, 48, 0, 2, 0),\n",
       " (10, 0, 2, 0, 0, 0, 11, 0, 0, 0),\n",
       " (11, 0, 0, 0, 0, 0, 2, 0, 0, 0),\n",
       " (2, 0, 0, 0, 0, 0, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8bfcb70-71e4-4548-9dd0-dc720c9352a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = binarymatrix(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d1bf33b-4fff-417b-be94-c661d506eed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       " [1, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e05ccf0-f8a4-48b1-802a-8f511aa09fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns padded input sequence tensor as well as tensor of lengths for each of the padded seq in the batc\n",
    "def inputVar(l:list, vocab:vocabulary):\n",
    "    indexes_batch = [indexfromSentance(vocab, sentance) for sentance in l]\n",
    "    lengths = torch.tensor([len(index_array) for index_array in indexes_batch])\n",
    "    padlist = zeropading(indexes_batch)\n",
    "    padvar = torch.LongTensor(padlist)\n",
    "    return padvar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35df8b76-8349-4a6b-8722-b17ae19f4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns padded target sequence tensor, padding mask and maax target length\n",
    "def outputVar(l:list, vocab:vocabulary):\n",
    "    indexes_batch = [indexfromSentance(vocab, sentance) for sentance in l]\n",
    "    max_target_len = max([len(index_array) for index_array in indexes_batch])\n",
    "    padlist = zeropading(indexes_batch)\n",
    "    mask = binarymatrix(padlist)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padvar = torch.LongTensor(padlist)\n",
    "    return padvar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9983aa17-2a38-4f94-bcfe-bf516ef47169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepares the data for training for a given batch of pairs\n",
    "def batch2traindata(vocab, pair_batch):\n",
    "    #Sort the question answers pairs in descending order\n",
    "    pair_batch.sort(key=lambda x:len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, vocab)\n",
    "    output, mask, max_target_len = outputVar(output_batch, vocab)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5c2d509-369a-4e4e-a5b4-55d2c9bee942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation of preprocessing steps\n",
    "batch_size = 5\n",
    "input_seq, lengths, target_seq, target_mask, max_target_length = batch2traindata(corpus, [random.choice(cleaned_pairs) for _ in range(batch_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a01ceb19-616e-4992-a735-2b57bffb7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 153,  113,   34,  550, 1483],\n",
      "        [  34,   34,  108, 6394,   16],\n",
      "        [ 101,   67,  285,   16,    2],\n",
      "        [ 102,  882,    6,    2,    0],\n",
      "        [ 307, 1114,  158,    0,    0],\n",
      "        [  82,  225,   11,    0,    0],\n",
      "        [  60,   16,    2,    0,    0],\n",
      "        [ 246,    2,    0,    0,    0],\n",
      "        [  11,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b39daa5-24b2-4f3e-baf1-ac9e625353b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  8,  7,  4,  3])\n"
     ]
    }
   ],
   "source": [
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad0da604-0c9b-4783-a62b-437d9e34136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 860,  344,  327,   66,  266],\n",
      "        [8058, 1184, 1544, 3183,   32],\n",
      "        [ 640,   11, 2398,   67,   11],\n",
      "        [  11,   17,   27, 6263,  143],\n",
      "        [   2,  543,   93,   73,   10],\n",
      "        [   0,  183,   11,    2,   16],\n",
      "        [   0,  522,    2,    0,    2],\n",
      "        [   0,   47,    0,    0,    0],\n",
      "        [   0, 1704,    0,    0,    0],\n",
      "        [   0,   11,    0,    0,    0],\n",
      "        [   0,    2,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a719f60a-6d6a-42e8-be88-db42edc41ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f65e55af-3c3c-4fae-b2f2-80608b4a7769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8010e9a-4b3a-4839-aece-432e3aefb6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
