{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f37d24-8bf9-4dcf-8fc4-1212d3bdf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from Vocabulary import vocabulary\n",
    "import pickle\n",
    "from preprocessing import normalizeString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a1ff985-3fb8-443b-982e-709319412873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading app vocabulary\n",
    "vocab_path = \"training_runs/chatbot_1/vocab.pkl\"\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#initializing models\n",
    "embedding = nn.Embedding(vocab.num_words, 512)\n",
    "encoder = Encoder(512,embedding,2,0.1)\n",
    "decoder = Decoder(\"dot\", embedding, 512, vocab.num_words, 2, 0.1)\n",
    "#loading appropriate weights\n",
    "missing, unexpected = encoder.load_state_dict(torch.load(\"training_runs/chatbot_1/train_10/encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"training_runs/chatbot_2/train_10/decoder.pth\"))\n",
    "# embedding.load_state_dict(torch.load(\"training_runs/chatbot_2/train_50/embedding.pth\"))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c111363-07ef-4129-9132-3c2a1092eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77433cdb-02dc-4793-b86e-ccb596c70dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentance = normalizeString(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f10d23f0-11bc-405b-b2ea-137dc36d4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_batch = [vocab.indexfromSentance(sentance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a54054c-a2ce-4129-a44a-657d4e188f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[855, 2]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9383471-e760-443d-9028-44c9f43978f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # make (batch, seq_len) -> (seq_len, batch)\n",
    "input_batch = torch.LongTensor(indexes_batch).transpose(0,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d09838d-2082-4629-bad4-342fa73d8878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18d60ad1-4814-42d1-a30c-7406379e5c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56a6a54b-d335-4bcc-adb2-773621a7b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(input_batch, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d11e83f-2cb3-406a-bf31-7113198132de",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden = encoder_hidden[:decoder.n_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3fb40e7b-4672-4a26-b48a-193e893da1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = torch.ones(1,1, device=device, dtype=torch.long) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb94cccf-66d2-4121-bcf3-8352d537e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititalize tensors to append decoded words to\n",
    "all_tokens = torch.zeros(0, device=device, dtype=torch.long)\n",
    "all_scores = torch.zeros(0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "371fc6ae-83ae-496a-b2d4-fbf270163358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c761218-71f7-40c9-81e9-26d925775af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(11):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "    decoder_input = torch.multinomial(decoder_output,1)\n",
    "    all_tokens = torch.cat((all_tokens, decoder_input), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db121802-3c71-4ef4-9ff0-a6d5e23f4788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  34],\n",
       "        [ 872],\n",
       "        [ 102],\n",
       "        [  11],\n",
       "        [  18],\n",
       "        [   8],\n",
       "        [2184],\n",
       "        [1724],\n",
       "        [  11],\n",
       "        [   2],\n",
       "        [   0]], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63961bd4-3b52-4e76-b18f-2cf7924bd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_words = [vocab.index2word[token.item()] for token in all_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a4ec7b6-1ef4-420d-b71c-d4bbfd2373c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'couldn', 't', '.', 'have', 'a', 'flower', 'feed', '.', 'EOS', 'PAD']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f686a906-af31-4eb0-926d-ef635d0edf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9030])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shapea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5202a47b-f6fe-4ad8-91b8-5206bb9d55e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0930], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([34], device='cuda:0'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(decoder_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf611dbd-8566-46f0-a06c-81497da2b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index2word[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97ee0df3-2e4b-468b-88ca-3347532b6b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(decoder_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e65aac34-be9b-4619-b23a-ab13e3ef0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = torch.multinomial(decoder_output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2be8d865-916a-4ce5-86e5-f756d0a223f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index2word[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5eff2e6-1901-41d9-9c4c-4ad6fe5c00b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a9128-fb22-458c-8aef-8352aa7924fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
