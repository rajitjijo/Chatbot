{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f37d24-8bf9-4dcf-8fc4-1212d3bdf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from Vocabulary import vocabulary\n",
    "import pickle\n",
    "from preprocessing import normalizeString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a1ff985-3fb8-443b-982e-709319412873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading app vocabulary\n",
    "vocab_path = \"training_runs/chatbot_1/vocab.pkl\"\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#initializing models\n",
    "embedding = nn.Embedding(vocab.num_words, 512)\n",
    "encoder = Encoder(512,embedding,2,0.1)\n",
    "decoder = Decoder(\"dot\", embedding, 512, vocab.num_words, 2, 0.1)\n",
    "#loading appropriate weights\n",
    "missing, unexpected = encoder.load_state_dict(torch.load(\"training_runs/chatbot_1/train_10/encoder.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"training_runs/chatbot_2/train_10/decoder.pth\"))\n",
    "# embedding.load_state_dict(torch.load(\"training_runs/chatbot_2/train_50/embedding.pth\"))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c111363-07ef-4129-9132-3c2a1092eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77433cdb-02dc-4793-b86e-ccb596c70dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentance = normalizeString(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f10d23f0-11bc-405b-b2ea-137dc36d4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_batch = [vocab.indexfromSentance(sentance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a54054c-a2ce-4129-a44a-657d4e188f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[855, 2]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9383471-e760-443d-9028-44c9f43978f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # make (batch, seq_len) -> (seq_len, batch)\n",
    "input_batch = torch.LongTensor(indexes_batch).transpose(0,1).to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d09838d-2082-4629-bad4-342fa73d8878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18d60ad1-4814-42d1-a30c-7406379e5c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56a6a54b-d335-4bcc-adb2-773621a7b516",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m encoder_output, encoder_hidden = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Chatbot\\model.py:27\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, input_seq, input_lengths, hidden)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03minput_seq: batch of input sentances with shape: (seq_length, batch_size)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03minput_lengths: list of sentance lengths corresponding to each sentance in the batch, so that we can avoid the padded values needed in packing padded sequence\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33;03mhidden: Hidden state for the last time step of shape = (n_layers x no_of_directions, batch_size, hidden_size)\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Conver word to word_embedding\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Pack padded batch of sequence for RNN Moduke\u001b[39;00m\n\u001b[32m     29\u001b[39m x = nn.utils.rnn.pack_padded_sequence(x, input_lengths)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "encoder_output, encoder_hidden = encoder(input_batch, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e717679b-9cc8-4f5d-ac68-33bbecb3c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = encoder_output.to(device)\n",
    "encoder_hidden = encoder_hidden.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d11e83f-2cb3-406a-bf31-7113198132de",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden = encoder_hidden[:decoder.n_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fb40e7b-4672-4a26-b48a-193e893da1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = torch.ones(1,1, device=device, dtype=torch.long) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb94cccf-66d2-4121-bcf3-8352d537e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inititalize tensors to append decoded words to\n",
    "all_tokens = torch.zeros(0, device=device, dtype=torch.long)\n",
    "all_scores = torch.zeros(0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "371fc6ae-83ae-496a-b2d4-fbf270163358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c761218-71f7-40c9-81e9-26d925775af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(11):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "    decoder_input = torch.multinomial(decoder_output,1)\n",
    "    all_tokens = torch.cat((all_tokens, decoder_input), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db121802-3c71-4ef4-9ff0-a6d5e23f4788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[119],\n",
       "        [ 74],\n",
       "        [ 47],\n",
       "        [102],\n",
       "        [ 11],\n",
       "        [  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63961bd4-3b52-4e76-b18f-2cf7924bd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_words = [vocab.index2word[token.item()] for token in all_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a4ec7b6-1ef4-420d-b71c-d4bbfd2373c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'not',\n",
       " 'to',\n",
       " 't',\n",
       " '.',\n",
       " 'EOS',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD',\n",
       " 'PAD']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f686a906-af31-4eb0-926d-ef635d0edf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9030])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shapea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5202a47b-f6fe-4ad8-91b8-5206bb9d55e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0930], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([34], device='cuda:0'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(decoder_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf611dbd-8566-46f0-a06c-81497da2b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index2word[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97ee0df3-2e4b-468b-88ca-3347532b6b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(decoder_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e65aac34-be9b-4619-b23a-ab13e3ef0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = torch.multinomial(decoder_output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2be8d865-916a-4ce5-86e5-f756d0a223f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index2word[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5eff2e6-1901-41d9-9c4c-4ad6fe5c00b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a9128-fb22-458c-8aef-8352aa7924fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
